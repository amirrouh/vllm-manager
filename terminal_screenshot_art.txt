╔══════════════════════════════════════════════════════════════════════════════╗
║                          VLLM Terminal Manager                              ║
╠══════════════════════════════════════════════════════════════════════════════╣
║                                                                              ║
║  🖥️  GPU Status: NVIDIA RTX 4090 [8192MB/24576MB used] [33% utilization]   ║
║  🌡️  Temperature: 42°C                                                       ║
║                                                                              ║
║  🤖 MODELS:                                                                  ║
║                                                                              ║
║  🟢 llama3-8b    [PID: 1234] [Port: 8001] [Priority: 1]                    ║
║       Status: Running | GPU: 2048MB | CPU: 2.3% | Uptime: 2h 15m           ║
║                                                                              ║
║  🟡 mistral-7b   [PID: ----] [Port: 8002] [Priority: 2]                    ║
║       Status: Starting...                                                   ║
║                                                                              ║
║  ⚫ codellama     [PID: ----] [Port: 8003] [Priority: 4]                    ║
║       Status: Stopped                                                       ║
║                                                                              ║
║  🎮 CONTROLS:                                                                ║
║    ↑/↓ Navigate | Enter Start/Stop | a Add | d Delete | c Cleanup | q Quit  ║
║                                                                              ║
╚══════════════════════════════════════════════════════════════════════════════╝